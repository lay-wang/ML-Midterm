import os, json, argparse, numpy as np, torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.optim import AdamW
from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingWarmRestarts
from tqdm import tqdm
import torchvision.transforms as transforms
import torch.nn.functional as F

from .utils.seed import set_seed
from .utils.data import PairNPZDataset

class OptimizedCompareNet(nn.Module):
    """é’ˆå¯¹GPUä¼˜åŒ–çš„é«˜æ•ˆæ¯”è¾ƒç½‘ç»œ"""
    def __init__(self, feat_dim=256):
        super().__init__()
        
        # å…±äº«ç‰¹å¾æå–å™¨
        self.feature_extractor = nn.Sequential(
            # ç¬¬ä¸€å±‚
            nn.Conv2d(1, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 14x14
            
            # ç¬¬äºŒå±‚
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 7x7
            
            # ç¬¬ä¸‰å±‚
            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((1, 1)),  # 1x1
        )
        
        # ç‰¹å¾æŠ•å½±
        self.feature_proj = nn.Sequential(
            nn.Flatten(),
            nn.Linear(256, feat_dim),
            nn.BatchNorm1d(feat_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
        )
        
        # æ¯”è¾ƒå¤´
        self.comparison_head = nn.Sequential(
            nn.Linear(feat_dim * 2, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.4),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(128, 1)
        )
        
        # å·®å¼‚å¤´
        self.diff_head = nn.Sequential(
            nn.Linear(feat_dim, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 1)
        )
    
    def forward(self, xa, xb):
        # ç‰¹å¾æå–
        fa = self.feature_extractor(xa)
        fb = self.feature_extractor(xb)
        
        # ç‰¹å¾æŠ•å½±
        fa_feat = self.feature_proj(fa)
        fb_feat = self.feature_proj(fb)
        
        # ä¸»è¦æ¯”è¾ƒåˆ†æ”¯
        combined = torch.cat([fa_feat, fb_feat], dim=-1)
        main_logit = self.comparison_head(combined).squeeze(1)
        
        # å·®å¼‚åˆ†æ”¯
        diff = torch.abs(fa_feat - fb_feat)
        diff_logit = self.diff_head(diff).squeeze(1)
        
        # ç»„åˆè¾“å‡º
        final_logit = main_logit + 0.3 * diff_logit
        
        return final_logit

class OptimizedAugmentedDataset(PairNPZDataset):
    """ä¼˜åŒ–çš„æ•°æ®å¢å¼ºæ•°æ®é›†"""
    def __init__(self, path_npz, is_train=False):
        super().__init__(path_npz, is_train)
        if is_train:
            self.transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.RandomRotation(degrees=8),
                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
                transforms.ColorJitter(brightness=0.2, contrast=0.2),
                transforms.ToTensor(),
            ])
        else:
            self.transform = None
    
    def __getitem__(self, idx):
        img = self.x[idx]  # (28,56)
        xa = img[:, :28]
        xb = img[:, 28:]
        
        # è½¬æ¢ä¸ºtensorå¹¶å½’ä¸€åŒ–
        xa = torch.from_numpy(xa).float().unsqueeze(0) / 255.0
        xb = torch.from_numpy(xb).float().unsqueeze(0) / 255.0
        
        # åº”ç”¨æ•°æ®å¢å¼ºï¼ˆä»…è®­ç»ƒæ—¶ï¼‰
        if self.transform is not None:
            xa_pil = xa.squeeze(0).numpy() * 255
            xb_pil = xb.squeeze(0).numpy() * 255
            xa_pil = np.stack([xa_pil] * 3, axis=-1).astype(np.uint8)
            xb_pil = np.stack([xb_pil] * 3, axis=-1).astype(np.uint8)
            
            xa_aug = self.transform(xa_pil)[0:1]
            xb_aug = self.transform(xb_pil)[0:1]
            
            xa = xa_aug
            xb = xb_aug
        
        if self.y is None:
            return xa, xb, self.ids[idx]
        else:
            y = int(self.y[idx])
            return xa, xb, y

def evaluate(model, loader, device):
    model.eval()
    ys, ps = [], []
    with torch.no_grad():
        for xa, xb, y in loader:
            xa = xa.to(device, non_blocking=True)
            xb = xb.to(device, non_blocking=True)
            y = y.to(device, non_blocking=True).float()
            
            logit = model(xa, xb)
            prob = torch.sigmoid(logit)
            pred = (prob >= 0.5).long()
            ys.append(y.long().cpu().numpy())
            ps.append(pred.cpu().numpy())
    
    y_true = np.concatenate(ys)
    y_pred = np.concatenate(ps)
    acc = (y_true == y_pred).mean().item()
    
    # macro-F1
    f1s = []
    for cls in [0,1]:
        tp = np.sum((y_true==cls) & (y_pred==cls))
        fp = np.sum((y_true!=cls) & (y_pred==cls))
        fn = np.sum((y_true==cls) & (y_pred!=cls))
        prec = tp / (tp + fp + 1e-12)
        rec  = tp / (tp + fn + 1e-12)
        f1 = 2 * prec * rec / (prec + rec + 1e-12)
        f1s.append(f1)
    f1_macro = float(np.mean(f1s))
    return acc, f1_macro

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--data_dir", type=str, required=True)
    ap.add_argument("--out_dir", type=str, default="./outputs/gpu_optimized")
    ap.add_argument("--epochs", type=int, default=100)
    ap.add_argument("--batch_size", type=int, default=128)
    ap.add_argument("--lr", type=float, default=3e-4)
    ap.add_argument("--weight_decay", type=float, default=1e-5)
    ap.add_argument("--seed", type=int, default=42)
    ap.add_argument("--num_workers", type=int, default=8)
    ap.add_argument("--patience", type=int, default=20)
    ap.add_argument("--feat_dim", type=int, default=256)
    args = ap.parse_args()

    os.makedirs(args.out_dir, exist_ok=True)
    set_seed(args.seed)

    # GPUè®¾ç½®å’Œä¼˜åŒ–
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        # è®¾ç½®GPUä¼˜åŒ–
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        scaler = torch.cuda.amp.GradScaler()
        use_amp = True
    else:
        device = torch.device("cpu")
        print("ä½¿ç”¨CPU")
        use_amp = False
    
    # åˆ›å»ºæ¨¡å‹
    model = OptimizedCompareNet(feat_dim=args.feat_dim).to(device)
    n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {n_params:,}")

    train_path = os.path.join(args.data_dir, "train.npz")
    val_path   = os.path.join(args.data_dir, "val.npz")
    
    # æ•°æ®é›†
    train_ds = OptimizedAugmentedDataset(train_path, is_train=True)
    val_ds   = PairNPZDataset(val_path, is_train=False)

    # ä¼˜åŒ–DataLoaderè®¾ç½®
    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, 
                             num_workers=args.num_workers, pin_memory=True,
                             persistent_workers=True if args.num_workers > 0 else False,
                             drop_last=True)
    val_loader   = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, 
                             num_workers=args.num_workers, pin_memory=True,
                             persistent_workers=True if args.num_workers > 0 else False)

    # ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    optim = AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    scheduler = CosineAnnealingWarmRestarts(optim, T_0=10, T_mult=2, eta_min=args.lr/10)
    criterion = torch.nn.BCEWithLogitsLoss()

    best = {"acc":0.0, "f1":0.0, "epoch":-1}
    patience, bad = args.patience, 0

    print(f"å¼€å§‹è®­ç»ƒï¼Œç›®æ ‡å‡†ç¡®ç‡: 80%")
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_ds)}, éªŒè¯é›†å¤§å°: {len(val_ds)}")
    print(f"ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ: {use_amp}")

    for epoch in range(1, args.epochs+1):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        pbar = tqdm(train_loader, desc=f"Epoch {epoch}")
        
        for xa, xb, y in pbar:
            xa = xa.to(device, non_blocking=True)
            xb = xb.to(device, non_blocking=True)
            y = y.to(device, non_blocking=True).float()
            
            optim.zero_grad()
            
            if use_amp:
                with torch.cuda.amp.autocast():
                    logit = model(xa, xb)
                    loss = criterion(logit, y)
                
                scaler.scale(loss).backward()
                scaler.unscale_(optim)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                scaler.step(optim)
                scaler.update()
            else:
                logit = model(xa, xb)
                loss = criterion(logit, y)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optim.step()
            
            train_loss += loss.item()
            pbar.set_postfix(loss=float(loss.item()))

        scheduler.step()
        avg_train_loss = train_loss / len(train_loader)

        # éªŒè¯é˜¶æ®µ
        val_acc, val_f1 = evaluate(model, val_loader, device)
        
        current_lr = optim.param_groups[0]['lr']
        print(f"[Epoch {epoch}] Train Loss: {avg_train_loss:.4f}, Val Acc: {val_acc:.4f}, "
              f"Val F1: {val_f1:.4f}, LR: {current_lr:.2e}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best["acc"]:
            best = {"acc":val_acc, "f1":val_f1, "epoch":epoch}
            torch.save(model.state_dict(), os.path.join(args.out_dir, "model.pt"))
            with open(os.path.join(args.out_dir, "metrics.json"), "w") as f:
                json.dump({
                    "best_val_acc": val_acc, 
                    "best_val_f1": val_f1, 
                    "best_epoch": epoch, 
                    "params": n_params,
                    "model_type": "optimized",
                    "use_amp": use_amp
                }, f, indent=2)
            bad = 0
            print(f"âœ“ æ–°çš„æœ€ä½³æ¨¡å‹ä¿å­˜! å‡†ç¡®ç‡: {val_acc:.4f}")
        else:
            bad += 1
            if bad >= patience:
                print(f"æ—©åœè§¦å‘ï¼Œæœ€ä½³å‡†ç¡®ç‡: {best['acc']:.4f}")
                break

    print(f"\nè®­ç»ƒå®Œæˆ!")
    print(f"æœ€ä½³ç»“æœ @ epoch {best['epoch']}: acc={best['acc']:.4f}, f1_macro={best['f1']:.4f}")
    print(f"ç›®æ ‡å‡†ç¡®ç‡: 80%, å½“å‰æœ€ä½³: {best['acc']*100:.2f}%")
    
    if best['acc'] >= 0.8:
        print("ğŸ‰ è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡!")
    else:
        print(f"âŒ æœªè¾¾åˆ°ç›®æ ‡ï¼Œè¿˜éœ€è¦æå‡ {0.8-best['acc']:.4f}")

if __name__ == "__main__":
    main()
